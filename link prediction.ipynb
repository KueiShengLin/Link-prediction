{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import random\n",
    "import community as luvain\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 154836 entries, 0 to 154835\n",
      "Data columns (total 3 columns):\n",
      "year         154836 non-null int64\n",
      "source id    154836 non-null int64\n",
      "target id    154836 non-null int64\n",
      "dtypes: int64(3)\n",
      "memory usage: 3.5 MB\n"
     ]
    }
   ],
   "source": [
    "period1 = pd.read_csv('dataset/Period1.csv')\n",
    "period2 = pd.read_csv('dataset/Period2.csv')\n",
    "test_data = pd.read_csv('dataset/TestData.csv')\n",
    "period1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "period1  node: 17028 edge: 154836\n",
      "period2  node: 15565 edge: 98353\n",
      "period_all  node: 23237 edge: 253189\n",
      "period_test  node: 23237 edge: 253189\n"
     ]
    }
   ],
   "source": [
    "def find_unique_node(input_node_set1, input_node_set2):\n",
    "    node_set = pd.concat([input_node_set1, input_node_set2], ignore_index=True)\n",
    "    node_set_unique = node_set.loc[node_set.duplicated() == False]\n",
    "    node_set_unique = node_set_unique.reset_index(drop=True)\n",
    "    return node_set_unique\n",
    "\n",
    "\n",
    "period1_node_unique = find_unique_node(period1['source id'], period1['target id'])\n",
    "period2_node_unique = find_unique_node(period2['source id'], period2['target id'])\n",
    "period_all_node_unique = find_unique_node(period1_node_unique, period2_node_unique)\n",
    "\n",
    "# Format edge to newortkx type\n",
    "period1_edge = [(period1.loc[i, 'source id'], period1.loc[i, 'target id']) for i in range(len(period1))]\n",
    "period2_edge = [(period2.loc[i, 'source id'], period2.loc[i, 'target id']) for i in range(len(period2))]\n",
    "period_all_edge = period1_edge + period2_edge\n",
    "\n",
    "\n",
    "print('period1 ', 'node:', len(period1_node_unique.values), 'edge:', len(period1_edge))\n",
    "print('period2 ', 'node:', len(period2_node_unique.values), 'edge:', len(period2_edge))\n",
    "print('period_all ', 'node:', len(period_all_node_unique.values), 'edge:', len(period_all_edge))\n",
    "print('period_test ', 'node:', len(period_all_node_unique.values), 'edge:', len(period_all_edge))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node: 23237 edge: 154698\n"
     ]
    }
   ],
   "source": [
    "# Network generate (period1)\n",
    "network_period1 = nx.Graph()\n",
    "# Add nodes\n",
    "network_period1.add_nodes_from(period_all_node_unique.values)\n",
    "# Add edges\n",
    "network_period1.add_edges_from(period1_edge)\n",
    "\n",
    "print('node:', network_period1.number_of_nodes(), 'edge:', network_period1.number_of_edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# network graph\n",
    "sub_graph = network_period1.subgraph(list(period1_node_unique[0:100]))   # 原圖太大取前幾個邊出來畫\n",
    "pos = nx.spring_layout(sub_graph)  # 圖的畫法\n",
    "nx.draw(sub_graph, pos=pos, node_size=40, vim=0.0, vmax=1.0, node_color=\"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node: 23237 edge: 252854\n"
     ]
    }
   ],
   "source": [
    "# Network generate (period_all)\n",
    "network_all = nx.Graph()\n",
    "# Add nodes\n",
    "network_all.add_nodes_from(period_all_node_unique.values)\n",
    "# Add edges\n",
    "network_all.add_edges_from(period_all_edge)\n",
    "print('node:', network_all.number_of_nodes(), 'edge:', network_all.number_of_edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# common neighbor score (neighbor = 1 best)\n",
    "def common_neighbor(network, input_node1, input_node2): \n",
    "    source_neighbor = [n for n in network.neighbors(input_node1)]\n",
    "    target_neighbor = [n for n in network.neighbors(input_node2)]\n",
    "    intersection = list(set(source_neighbor) & set(target_neighbor))\n",
    "    return len(intersection)\n",
    "\n",
    "# Jaccard's cofficient\n",
    "def jaccard_cofficient(network, input_node1, input_node2):\n",
    "    cofficient = 0\n",
    "    source_neighbor = [n for n in network.neighbors(input_node1)]\n",
    "    target_neighbor = [n for n in network.neighbors(input_node2)]\n",
    "    union = list(set(source_neighbor) | set(target_neighbor))\n",
    "    intersection = list(set(source_neighbor) & set(target_neighbor))\n",
    "    if len(union) == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return (len(intersection) / len(union))\n",
    "\n",
    "\n",
    "# Adamic/Adar\n",
    "def adamic_adar(network, input_node1, input_node2):\n",
    "    adamic_score = 0\n",
    "    source_neighbor = [n for n in network.neighbors(input_node1)]\n",
    "    target_neighbor = [n for n in network.neighbors(input_node2)]\n",
    "    intersection = list(set(source_neighbor) & set(target_neighbor))\n",
    "    \n",
    "    if len(intersection) == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        for v in intersection:\n",
    "            adamic_score += 1 / math.log(len([nv for nv in network.neighbors(v)]))\n",
    "        return adamic_score\n",
    "\n",
    "\n",
    "# clustering coefficient\n",
    "def clustering_coefficient(network, input_node):\n",
    "    node_degree = network.degree[input_node]\n",
    "    node_triangle = nx.triangles(network, input_node)\n",
    "    if node_degree - 1 <= 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return (2 * node_triangle) / (node_degree * (node_degree - 1))   \n",
    "    \n",
    "\n",
    "# perferential attachment\n",
    "def perferential_attachment(network, input_node1, input_node2): \n",
    "    source_neighbor = len([n for n in network.neighbors(input_node1)])\n",
    "    target_neighbor = len([n for n in network.neighbors(input_node2)])\n",
    "    return {'pa_mul': source_neighbor * target_neighbor, 'pa_add': source_neighbor + target_neighbor}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Katz score\n",
    "def katz_score(network, input_node1, input_node2, beta=0.005):\n",
    "    score = 0\n",
    "    for cutoff in range(1, 5):\n",
    "        path_amount = 0\n",
    "        all_paths = nx.all_simple_paths(network, input_node1, input_node2, cutoff=cutoff)\n",
    "        for path in all_paths:\n",
    "            if path_amount > 100:\n",
    "                continue\n",
    "            else:\n",
    "                path_amount += 1\n",
    "                \n",
    "        score += (beta**cutoff) * path_amount\n",
    "    return score\n",
    "\n",
    "# katz_score = katz(network_test, test_data['source id'][709], test_data['target id'][709], beta=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>edge</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(3273, 9901003)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(10172, 9312198)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(9707193, 9609123)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(9061, 9805170)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(102045, 9901128)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 edge  label\n",
       "0     (3273, 9901003)      1\n",
       "1    (10172, 9312198)      0\n",
       "2  (9707193, 9609123)      0\n",
       "3     (9061, 9805170)      1\n",
       "4   (102045, 9901128)      1"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# step 2 geneate model\n",
    "# find period1 complement graph (使用補圖的所有edge 當training data才對，不過我電腦跑不動)\n",
    "# network_period1_complement = nx.complement(network_period1)\n",
    "# print(\"complement down\")\n",
    "# complement_edge = network_period1_complement.edges()\n",
    "\n",
    "# 直接使用period2裡面的當1，再從network_period1 亂數取幾個點，他們形成的補圖edge當0\n",
    "# period1 subgraph\n",
    "period1_not_in_2 = period1_node_unique.append(period2_node_unique).drop_duplicates(keep=False)\n",
    "period1_node_shuffle = random.Random(2).sample(list(period1_not_in_2), 450)\n",
    "sub_graph = network_period1.subgraph(period1_node_shuffle)\n",
    "sub_graph_complement = nx.complement(sub_graph)\n",
    "# pos = nx.spring_layout(sub_graph)  # 圖的畫法\n",
    "# nx.draw(sub_graph_complement, pos=pos, node_size=40, vim=0.0, vmax=1.0, node_color=\"red\")\n",
    "\n",
    "# tag label\n",
    "train_label = []\n",
    "# 注意順序\n",
    "for edge in period2_edge:\n",
    "    train_label.append(1)\n",
    "for edge in list(sub_graph_complement.edges()):\n",
    "    train_label.append(0)   \n",
    "\n",
    "train_data_edge = period2_edge + list(sub_graph_complement.edges())\n",
    "train_data = pd.DataFrame(data={'edge': train_data_edge, 'label': train_label})\n",
    "train_data = shuffle(train_data, random_state=32).reset_index(drop=True)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 199365\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-63-0078433b3ebf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;31m# path base\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[0mkatz\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkatz_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnetwrok_period2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0medge\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0medge\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m     \u001b[1;31m# other\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0msource_cc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclustering_coefficient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnetwrok_period2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0medge\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-61-639cd63a7479>\u001b[0m in \u001b[0;36mkatz_score\u001b[1;34m(network, input_node1, input_node2, beta)\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mpath_amount\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mall_paths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall_simple_paths\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_node1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_node2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcutoff\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcutoff\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mall_paths\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpath_amount\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m                 \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mI:\\anaconda\\lib\\site-packages\\networkx\\algorithms\\simple_paths.py\u001b[0m in \u001b[0;36m_all_simple_paths_graph\u001b[1;34m(G, source, target, cutoff)\u001b[0m\n\u001b[0;32m    221\u001b[0m             \u001b[0mstack\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m             \u001b[0mvisited\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 223\u001b[1;33m         \u001b[1;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvisited\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mcutoff\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    224\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mchild\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m                 \u001b[1;32myield\u001b[0m \u001b[0mvisited\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "# train data feature\n",
    "cn, jaccard, adamic, cc_mul, cc_add, pa_mul, pa_add = [],[], [], [], [], [], []\n",
    "katz = []\n",
    "source_id, target_id = [], []\n",
    "\n",
    "netwrok_period2 = network_period1\n",
    "netwrok_period2.add_nodes_from(period2_node_unique)\n",
    "\n",
    "for edge_id, edge in enumerate(train_data['edge'].values):\n",
    "    source_id.append(edge[0])\n",
    "    target_id.append(edge[1])\n",
    "    \n",
    "    # neighbor base\n",
    "    cn.append(common_neighbor(netwrok_period2, edge[0], edge[1]))\n",
    "    jaccard.append(jaccard_cofficient(netwrok_period2, edge[0], edge[1]))\n",
    "    adamic.append(adamic_adar(netwrok_period2, edge[0], edge[1]))\n",
    "    \n",
    "    # path base\n",
    "    katz.append(katz_score(netwrok_period2, edge[0], edge[1]))\n",
    "    # other\n",
    "    source_cc = clustering_coefficient(netwrok_period2, edge[0])\n",
    "    target_cc = clustering_coefficient(netwrok_period2, edge[1])\n",
    "    cc_mul.append(source_cc * target_cc)\n",
    "    cc_add.append(source_cc + target_cc)\n",
    "    pa = perferential_attachment(netwrok_period2, edge[0], edge[1])\n",
    "    pa_mul.append(pa['pa_mul'])\n",
    "    pa_add.append(pa['pa_add'])\n",
    "    \n",
    "    if edge_id % 10000 == 0:\n",
    "        print(edge_id, len(train_data))\n",
    "# \n",
    "train_data['source id'] = pd.Series(source_id, index=train_data.index)\n",
    "train_data['target id'] = pd.Series(target_id, index=train_data.index)\n",
    "train_data['cn'] = pd.Series(cn, index=train_data.index)\n",
    "train_data['jaccard'] = pd.Series(jaccard, index=train_data.index)\n",
    "train_data['adamic'] = pd.Series(adamic, index=train_data.index)\n",
    "train_data['cc_mul'] = pd.Series(cc_mul, index=train_data.index)\n",
    "train_data['cc_add'] = pd.Series(cc_add, index=train_data.index)\n",
    "train_data['pa_mul'] = pd.Series(pa_mul, index=train_data.index)\n",
    "train_data['pa_add'] = pd.Series(pa_add, index=train_data.index)\n",
    "train_data['katz'] = pd.Series(katz, index=train_data.index)\n",
    "train_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save train data\n",
    "train_data_bye = train_data.drop('edge', axis=1)\n",
    "train_data_bye.to_csv(\"train_data_real.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load train data\n",
    "train_data = pd.read_csv(\"train_data_real.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gogogo\n",
      "0 199365\n",
      "10000 199365\n",
      "20000 199365\n",
      "30000 199365\n",
      "40000 199365\n",
      "50000 199365\n",
      "60000 199365\n",
      "70000 199365\n",
      "80000 199365\n",
      "90000 199365\n",
      "100000 199365\n",
      "110000 199365\n",
      "120000 199365\n",
      "130000 199365\n",
      "140000 199365\n",
      "150000 199365\n",
      "160000 199365\n",
      "170000 199365\n",
      "180000 199365\n",
      "190000 199365\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>source id</th>\n",
       "      <th>target id</th>\n",
       "      <th>cn</th>\n",
       "      <th>jaccard</th>\n",
       "      <th>adamic</th>\n",
       "      <th>cc_mul</th>\n",
       "      <th>cc_add</th>\n",
       "      <th>pa_mul</th>\n",
       "      <th>pa_add</th>\n",
       "      <th>katz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3273</td>\n",
       "      <td>9901003</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.352632</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>10172</td>\n",
       "      <td>9312198</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>9707193</td>\n",
       "      <td>9609123</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.351724</td>\n",
       "      <td>60</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>9061</td>\n",
       "      <td>9805170</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.198859</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>102045</td>\n",
       "      <td>9901128</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.148867</td>\n",
       "      <td>0</td>\n",
       "      <td>103</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>9410076</td>\n",
       "      <td>9705028</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>48</td>\n",
       "      <td>19</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>111284</td>\n",
       "      <td>9808095</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.337662</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>8127</td>\n",
       "      <td>3220</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>107149</td>\n",
       "      <td>9806106</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.148148</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>4186</td>\n",
       "      <td>9804123</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.211429</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  source id  target id  cn  jaccard  adamic  cc_mul    cc_add  pa_mul  \\\n",
       "0      1       3273    9901003   0      0.0     0.0    0.00  0.352632       0   \n",
       "1      0      10172    9312198   0      0.0     0.0    0.00  0.266667       0   \n",
       "2      0    9707193    9609123   0      0.0     0.0    0.00  0.351724      60   \n",
       "3      1       9061    9805170   0      0.0     0.0    0.00  0.198859       0   \n",
       "4      1     102045    9901128   0      0.0     0.0    0.00  0.148867       0   \n",
       "5      0    9410076    9705028   0      0.0     0.0    0.05  0.483333      48   \n",
       "6      1     111284    9808095   0      0.0     0.0    0.00  0.337662       0   \n",
       "7      1       8127       3220   0      0.0     0.0    0.00  0.000000       0   \n",
       "8      1     107149    9806106   0      0.0     0.0    0.00  0.148148       0   \n",
       "9      1       4186    9804123   0      0.0     0.0    0.00  0.211429       0   \n",
       "\n",
       "   pa_add  katz  \n",
       "0      20   0.0  \n",
       "1      10   0.0  \n",
       "2      32   0.0  \n",
       "3      68   0.0  \n",
       "4     103   0.0  \n",
       "5      19   0.0  \n",
       "6      22   0.0  \n",
       "7       0   0.0  \n",
       "8      27   0.0  \n",
       "9      50   0.0  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('gogogo')\n",
    "katz = []\n",
    "for edge_id, edge in enumerate(train_data_edge):\n",
    "    katz.append(katz_score(netwrok_period2, edge[0], edge[1]))\n",
    "    if edge_id % 10000 == 0:\n",
    "        print(edge_id, len(train_data))\n",
    "        \n",
    "train_data['katz'] = pd.Series(katz, index=train_data.index)\n",
    "train_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data_bye.to_csv(\"train_data_katz.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train feature (pa_add 爛\n",
    "feature = zip(train_data['cn'], train_data['jaccard'], train_data['adamic'], train_data['cc_mul'], train_data['cc_add'],\n",
    "              train_data['pa_mul'])\n",
    "feature = [[cn, jaccard, adamic, cc_mul, cc_add, pa_mul]\n",
    "           for cn, jaccard, adamic, cc_mul, cc_add, pa_mul in feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#SVM gogo\n",
    "svm = SVC()\n",
    "svm.fit(feature, train_data['label'].tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svm.predict([[0, 0, 0, 0, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Decision tree\n",
    "dt = tree.DecisionTreeClassifier()\n",
    "dt = dt.fit(feature, train_data['label'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Random forest\n",
    "rf = RandomForestClassifier(random_state=0,n_estimators=300)\n",
    "rf = dt.fit(feature, train_data['label'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# KNN\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn = knn.fit(feature, train_data['label'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "period_test  node: 31491 edge: 252854\n"
     ]
    }
   ],
   "source": [
    "# step 3 link predict\n",
    "# check test data is in network\n",
    "test_data_node_unique = find_unique_node(test_data['source id'], test_data['target id'])\n",
    "test_data_in_network = pd.concat([period_all_node_unique, test_data_node_unique], ignore_index=True)\n",
    "test_data_in_network = test_data_in_network.loc[test_data_in_network.duplicated() == True]\n",
    "test_data_in_network = test_data_in_network.reset_index(drop=True)\n",
    "\n",
    "\n",
    "# Add test data node & edge in network\n",
    "test_edge = [(test_data.loc[i, 'source id'], test_data.loc[i, 'target id']) for i in range(len(test_data))]\n",
    "network_test = network_all\n",
    "network_test.add_nodes_from(test_data_node_unique.values)\n",
    "# network_test.add_edges_from(test_edge)\n",
    "\n",
    "print('period_test ', 'node:', network_test.number_of_nodes(), 'edge:', network_test.number_of_edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "# test data feature \n",
    "neighbor_score_list = []\n",
    "for data_id, data in test_data.iterrows():\n",
    "    neighbor_score_list.append(common_neighbor(network_test, data['source id'], data['target id']))\n",
    "    \n",
    "print(neighbor_score_list[709])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07692307692307693\n"
     ]
    }
   ],
   "source": [
    "jaccard_score_list = []\n",
    "    \n",
    "for data_id, data in test_data.iterrows():\n",
    "    jaccard_score_list.append(jaccard_cofficient(network_test, data['source id'], data['target id']))\n",
    "        \n",
    "# Networkx jaccard_coefficient function\n",
    "# networkx_jaccard = []\n",
    "# fucking_list = []\n",
    "# \n",
    "# for data_id, data in test_data.iterrows():\n",
    "#     fucking_list.append(((data['source id'],data['target id'])))\n",
    "#     \n",
    "# preds = nx.jaccard_coefficient(network_all, fucking_list)\n",
    "# for u,v,p in preds:\n",
    "#     networkx_jaccard.append(p)\n",
    "# \n",
    "# print(networkx_jaccard[709])\n",
    "print(jaccard_score_list[709])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2312765119577433\n"
     ]
    }
   ],
   "source": [
    "adamic_score_list = []\n",
    "for data_id, data in test_data.iterrows():\n",
    "    adamic_score_list.append(adamic_adar(network_test, data['source id'], data['target id']))   \n",
    "\n",
    "\n",
    "# Networkx adamic_adar_index\n",
    "# networkx_adamic_adar_index = []\n",
    "# fucking_list = []\n",
    "# \n",
    "# for data_id, data in test_data.iterrows():\n",
    "#     fucking_list.append(((data['source id'],data['target id'])))\n",
    "# \n",
    "# preds = nx.adamic_adar_index(network_all, fucking_list)\n",
    "# for u, v, p in preds:\n",
    "#     networkx_adamic_adar_index.append(p)\n",
    "#     \n",
    "# print(networkx_adamic_adar_index[709])\n",
    "print(adamic_score_list[709])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0617702448210922\n"
     ]
    }
   ],
   "source": [
    "cc_mul_score_list = []\n",
    "cc_add_scroe_list = []\n",
    "for data_id, data in test_data.iterrows():\n",
    "    source_cc = clustering_coefficient(network_test, data['source id'])\n",
    "    target_cc = clustering_coefficient(network_test, data['target id'])\n",
    "    cc_mul_score_list.append(source_cc * target_cc) \n",
    "    cc_add_scroe_list.append(source_cc + target_cc)\n",
    "    \n",
    "# Networkx cc\n",
    "# networkx_cc = []\n",
    "# for data_id, data in test_data.iterrows():\n",
    "#     cc_score = nx.clustering(network_test, data['source id']) * nx.clustering(network_test, data['target id'])\n",
    "#     networkx_cc.append(cc_score)\n",
    "# \n",
    "# print(networkx_cc[709])\n",
    "\n",
    "print(cc_add_scroe_list[709])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600\n"
     ]
    }
   ],
   "source": [
    "pa_mul_score_list = []\n",
    "pa_add_scroe_list = []\n",
    "for data_id, data in test_data.iterrows():\n",
    "    pa = perferential_attachment(network_test, data['source id'], data['target id'])\n",
    "    pa_mul_score_list.append(pa['pa_mul'])\n",
    "    pa_add_scroe_list.append(pa['pa_add'])\n",
    "\n",
    "print(pa_mul_score_list[709])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "latz_score_list = []\n",
    "for data_id, data in test_data.iterrows():\n",
    "    katz = katz_score(network_test, data['source id'], data['target id'])\n",
    "    latz_score_list.append(katz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "# predict test data dt\n",
    "\n",
    "test_feature = [[n, j, a, cc_mul, cc_add, pa_mul, katz] for n, j, a, cc_mul, cc_add, pa_mul, katz in \n",
    "                zip(neighbor_score_list, jaccard_score_list, adamic_score_list, cc_mul_score_list, cc_add_scroe_list,\n",
    "                    pa_mul_score_list, latz_score_list)]\n",
    "\n",
    "predict = knn.predict(test_feature)\n",
    "print(len(predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# output predict\n",
    "row = [i for i in range(1, 10001)]\n",
    "label = []\n",
    "\n",
    "\n",
    "data = {'target id': row, 'label': label}\n",
    "predict = pd.DataFrame(data=data, columns=['target id', 'label'])\n",
    "predict.to_csv(\"predict/knn_nei_cc_real.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
